# GPU Shader ç²’å­è§†é¢‘ï¼ˆäººç‰©æ¸…æ™° Â· æ€§èƒ½æ‹‰æ»¡ç‰ˆï¼‰

## ä¸€ã€ç›®æ ‡ä¸æ•ˆæœ

### ğŸ¯ ç›®æ ‡

- ä½¿ç”¨ GPU Shader å®Œæˆè§†é¢‘ç²’å­åŒ–
- **10 ä¸‡çº§ç²’å­ç¨³å®š 60 FPS**
- äººç‰©åŒºåŸŸç²’å­æ›´æ¸…æ™°ï¼ŒèƒŒæ™¯ç²’å­æ›´è™š
- è§†é¢‘å†…å®¹ã€è¿åŠ¨å®Œå…¨ä¸€è‡´
- **CPU ä»…è´Ÿè´£**ï¼šè§†é¢‘è§£ç  + äººåƒåˆ†å‰²
- **GPU è´Ÿè´£**ï¼šé‡‡æ ·ã€ä¸Šè‰²ã€æ·±åº¦ã€ç²’å­å°ºå¯¸

### æœ€ç»ˆæ•ˆæœ

- âœ… 10 ä¸‡+ ç²’å­æµç•…è¿è¡Œ
- âœ… äººç‰©åŒºåŸŸï¼šç²’å­æ›´å¤§ã€æ›´æ¸…æ™°ã€æ›´é å‰
- âœ… èƒŒæ™¯åŒºåŸŸï¼šç²’å­æ›´å°ã€æ›´è™šã€æ›´é å
- âœ… å®æ—¶æ¸²æŸ“ï¼Œæ— å¡é¡¿

## äºŒã€ä¸ºä»€ä¹ˆå¿…é¡»ä¸Š GPU Shaderï¼Ÿ

### âŒ CPU ç‰ˆç“¶é¢ˆ

- JS å¾ªç¯å¤„ç†æ¯ä¸ªç²’å­
- æ¯å¸§æ›´æ–° BufferAttribute
- ç²’å­æ•° > 2 ä¸‡å°±å¼€å§‹æ‰å¸§
- CPU å ç”¨é«˜ï¼Œæµè§ˆå™¨å¡é¡¿

### âœ… GPU Shader ä¼˜åŠ¿

- ç²’å­ä½ç½®ä¸€æ¬¡æ€§åˆ›å»ºï¼ˆé™æ€ï¼‰
- æ¯å¸§åªæ›´æ–°è§†é¢‘çº¹ç†
- åƒç´ é‡‡æ ·ã€é¢œè‰²ã€æ·±åº¦å…¨éƒ¨åœ¨ GPU
- æ€§èƒ½ â‰ˆ åªå’Œå±å¹•åˆ·æ–°ç‡æœ‰å…³

### æœ¬è´¨

**Points + è‡ªå®šä¹‰ Shader = "è§†é¢‘åƒç´ çš„ GPU é‡ç»˜"**

## ä¸‰ã€æ•´ä½“æ¶æ„ï¼ˆGPU ç‰ˆï¼‰

```
Video Element
   â†“
VideoTextureï¼ˆGPUï¼‰
   â†“
Fragment Shader é‡‡æ ·è§†é¢‘é¢œè‰²
   â†“
Vertex Shader æ§åˆ¶ç²’å­ä½ç½® / å¤§å° / æ·±åº¦
   â†“
Pointsï¼ˆ10w+ ç²’å­ï¼‰
```

**äººç‰©è¯†åˆ«ï¼ˆCPUï¼‰åªåšä¸€ä»¶äº‹**ï¼š

```
MediaPipe â†’ äººåƒ Mask â†’ Mask Textureï¼ˆGPUï¼‰
```

## å››ã€æ ¸å¿ƒè®¾è®¡æ€è·¯ï¼ˆéå¸¸é‡è¦ï¼‰

### 1ï¸âƒ£ ç²’å­ â‰  è§†é¢‘å¸§

- **ç²’å­æ˜¯é™æ€ç½‘æ ¼**ï¼šä½ç½®åˆ›å»ºåä¸å†æ”¹å˜
- **è§†é¢‘æ˜¯åŠ¨æ€çº¹ç†**ï¼šæ¯å¸§æ›´æ–°çº¹ç†å†…å®¹

### 2ï¸âƒ£ Shader åšä¸‰ä»¶äº‹

- æ ¹æ®ç²’å­ UV â†’ é‡‡æ ·è§†é¢‘
- æ ¹æ® mask â†’ å†³å®šæ¸…æ™°åº¦
- æ ¹æ®äº®åº¦ â†’ å†³å®š Z æ·±åº¦

### 3ï¸âƒ£ çº¹ç†æ›´æ–°æœºåˆ¶

- è§†é¢‘çº¹ç†ï¼šè‡ªåŠ¨æ›´æ–°ï¼ˆVideoTextureï¼‰
- Mask çº¹ç†ï¼šMediaPipe æ›´æ–°åè®¾ç½® `needsUpdate = true`

## äº”ã€ç²’å­æ•°æ®è®¾è®¡ï¼ˆä¸€æ¬¡æ€§åˆ›å»ºï¼‰

```typescript
const width = 320
const height = 180
const count = width * height  // 57,600 ä¸ªç²’å­

const positions = new Float32Array(count * 3)
const uvs = new Float32Array(count * 2)

let i = 0
let j = 0

for (let y = 0; y < height; y++) {
  for (let x = 0; x < width; x++) {
    positions[i++] = x - width / 2
    positions[i++] = height / 2 - y
    positions[i++] = 0

    uvs[j++] = x / width
    uvs[j++] = y / height
  }
}
```

ğŸ‘‰ **ä½ç½®ä¸å†æ›´æ–°ï¼Œæ°¸è¿œé™æ€**

## å…­ã€ShaderMaterialï¼ˆæ ¸å¿ƒï¼‰

### ğŸ”¹ Vertex Shaderï¼ˆæ§åˆ¶ç²’å­ï¼‰

```glsl
uniform sampler2D uVideo;
uniform sampler2D uMask;
uniform float uTime;

varying vec2 vUv;
varying float vIsPerson;

void main() {
  vUv = uv;

  // é‡‡æ ·è§†é¢‘é¢œè‰²
  vec4 videoColor = texture2D(uVideo, uv);
  float brightness = (videoColor.r + videoColor.g + videoColor.b) / 3.0;

  // é‡‡æ · mask
  float mask = texture2D(uMask, uv).r;
  vIsPerson = mask;

  vec3 pos = position;

  // äººç‰©æ›´é å‰
  if (mask > 0.5) {
    pos.z += brightness * 60.0;  // äººç‰©ï¼šå¤§å¹…é å‰
  } else {
    pos.z += brightness * 15.0;   // èƒŒæ™¯ï¼šè½»å¾®é å
    // èƒŒæ™¯è½»å¾®æ¼‚æµ®ï¼ˆå¯é€‰ï¼‰
    pos.z += sin(uTime + position.x * 0.05) * 5.0;
  }

  gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);

  // ç²’å­å°ºå¯¸ï¼šäººç‰©æ›´å¤§
  gl_PointSize = mask > 0.5 ? 2.8 : 1.2;
}
```

### ğŸ”¹ Fragment Shaderï¼ˆæ§åˆ¶é¢œè‰²ï¼‰

```glsl
uniform sampler2D uVideo;

varying vec2 vUv;
varying float vIsPerson;

void main() {
  // é‡‡æ ·è§†é¢‘é¢œè‰²
  vec4 color = texture2D(uVideo, vUv);

  // åœ†å½¢ç²’å­ï¼ˆå¯é€‰ï¼Œæ›´æŸ”å’Œï¼‰
  float d = distance(gl_PointCoord, vec2(0.5));
  if (d > 0.5) discard;

  // èƒŒæ™¯é€æ˜åº¦æ›´ä½ï¼ˆæ›´è™šï¼‰
  float alpha = vIsPerson > 0.5 ? 1.0 : 0.45;

  gl_FragColor = vec4(color.rgb, alpha);
}
```

## ä¸ƒã€Three.js ShaderMaterial åˆå§‹åŒ–

```typescript
const material = new THREE.ShaderMaterial({
  uniforms: {
    uVideo: { value: videoTexture },
    uMask: { value: maskTexture },
    uTime: { value: 0 }
  },
  vertexShader: vertexShaderCode,
  fragmentShader: fragmentShaderCode,
  transparent: true,
  depthTest: true,
  depthWrite: false
})
```

## å…«ã€è§†é¢‘ä¸ Mask ä½œä¸ºçº¹ç†ï¼ˆå…³é”®ï¼‰

### ğŸ¥ è§†é¢‘çº¹ç†

```typescript
const videoTexture = new THREE.VideoTexture(video)
videoTexture.minFilter = THREE.LinearFilter
videoTexture.magFilter = THREE.LinearFilter
videoTexture.format = THREE.RGBAFormat
```

### ğŸ‘¤ äººåƒ Mask çº¹ç†

```typescript
const maskTexture = new THREE.CanvasTexture(maskCanvas)
maskTexture.minFilter = THREE.LinearFilter
maskTexture.magFilter = THREE.LinearFilter
```

**MediaPipe æ¯æ¬¡æ›´æ–° mask åªéœ€**ï¼š

```typescript
maskTexture.needsUpdate = true
```

## ä¹ã€å®Œæ•´å®ç°ä»£ç ï¼ˆReact/Next.jsï¼‰

```typescript
'use client'

import { useEffect, useRef, useState } from 'react'
import * as THREE from 'three'

interface ShaderVideoParticleProps {
  videoSrc: string
  width?: number
  height?: number
  particleSize?: number
  className?: string
}

// Vertex Shader
const vertexShader = `
uniform sampler2D uVideo;
uniform sampler2D uMask;
uniform float uTime;

varying vec2 vUv;
varying float vIsPerson;

void main() {
  vUv = uv;

  // é‡‡æ ·è§†é¢‘é¢œè‰²
  vec4 videoColor = texture2D(uVideo, uv);
  float brightness = (videoColor.r + videoColor.g + videoColor.b) / 3.0;

  // é‡‡æ · mask
  float mask = texture2D(uMask, uv).r;
  vIsPerson = mask;

  vec3 pos = position;

  // äººç‰©æ›´é å‰
  if (mask > 0.5) {
    pos.z += brightness * 60.0;  // äººç‰©ï¼šå¤§å¹…é å‰
  } else {
    pos.z += brightness * 15.0;   // èƒŒæ™¯ï¼šè½»å¾®é å
  }

  gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);

  // ç²’å­å°ºå¯¸ï¼šäººç‰©æ›´å¤§
  gl_PointSize = mask > 0.5 ? 2.8 : 1.2;
}
`

// Fragment Shader
const fragmentShader = `
uniform sampler2D uVideo;

varying vec2 vUv;
varying float vIsPerson;

void main() {
  // é‡‡æ ·è§†é¢‘é¢œè‰²
  vec4 color = texture2D(uVideo, vUv);

  // åœ†å½¢ç²’å­ï¼ˆå¯é€‰ï¼Œæ›´æŸ”å’Œï¼‰
  float d = distance(gl_PointCoord, vec2(0.5));
  if (d > 0.5) discard;

  // èƒŒæ™¯é€æ˜åº¦æ›´ä½ï¼ˆæ›´è™šï¼‰
  float alpha = vIsPerson > 0.5 ? 1.0 : 0.45;

  gl_FragColor = vec4(color.rgb, alpha);
}
`

export default function ShaderVideoParticle({
  videoSrc,
  width = 320,
  height = 180,
  particleSize = 2,
  className = ''
}: ShaderVideoParticleProps) {
  const containerRef = useRef<HTMLDivElement>(null)
  const videoRef = useRef<HTMLVideoElement>(null)
  const sceneRef = useRef<THREE.Scene | null>(null)
  const cameraRef = useRef<THREE.PerspectiveCamera | null>(null)
  const rendererRef = useRef<THREE.WebGLRenderer | null>(null)
  const particlesRef = useRef<THREE.Points | null>(null)
  const geometryRef = useRef<THREE.BufferGeometry | null>(null)
  const materialRef = useRef<THREE.ShaderMaterial | null>(null)
  const animationFrameRef = useRef<number>()
  const maskCanvasRef = useRef<HTMLCanvasElement | null>(null)
  const maskCtxRef = useRef<CanvasRenderingContext2D | null>(null)
  const videoTextureRef = useRef<THREE.VideoTexture | null>(null)
  const maskTextureRef = useRef<THREE.CanvasTexture | null>(null)
  const segmentationRef = useRef<any>(null)
  const personMaskRef = useRef<HTMLCanvasElement | null>(null)
  const lastSegTimeRef = useRef<number>(0)

  const [isPlaying, setIsPlaying] = useState(false)
  const [isLoading, setIsLoading] = useState(true)
  const [error, setError] = useState<string | null>(null)
  const [hasMask, setHasMask] = useState(false)

  useEffect(() => {
    if (!containerRef.current || !videoRef.current) return

    // åŠ¨æ€å¯¼å…¥ MediaPipeï¼ˆä»…åœ¨å®¢æˆ·ç«¯ï¼‰
    const initMediaPipe = async () => {
      try {
        const { SelfieSegmentation } = await import('@mediapipe/selfie_segmentation')
        
        const segmentation = new SelfieSegmentation({
          locateFile: (file: string) =>
            `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}`
        })

        segmentation.setOptions({
          modelSelection: 1 // 0ï¼šè¿‘æ™¯äººåƒï¼Œ1ï¼šå…¨èº«
        })

        segmentation.onResults((results: any) => {
          if (results.segmentationMask && maskTextureRef.current) {
            personMaskRef.current = results.segmentationMask
            setHasMask(true)
            // æ›´æ–° mask çº¹ç†
            maskTextureRef.current.needsUpdate = true
            console.log('MediaPipe mask å·²æ›´æ–°')
          }
        })

        segmentationRef.current = segmentation
        console.log('MediaPipe åˆå§‹åŒ–æˆåŠŸ')
      } catch (err) {
        console.warn('MediaPipe ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨åŸºç¡€ç²’å­æ•ˆæœ')
      }
    }

    initMediaPipe()

    // åˆå§‹åŒ– Three.js
    const scene = new THREE.Scene()
    sceneRef.current = scene

    const camera = new THREE.PerspectiveCamera(
      45,
      window.innerWidth / window.innerHeight,
      1,
      1000
    )
    camera.position.z = 400
    cameraRef.current = camera

    const renderer = new THREE.WebGLRenderer({ antialias: true })
    renderer.setSize(window.innerWidth, window.innerHeight)
    renderer.setClearColor(0x000000, 1)
    containerRef.current.appendChild(renderer.domElement)
    rendererRef.current = renderer

    // åˆ›å»º mask Canvas
    const maskCanvas = document.createElement('canvas')
    maskCanvas.width = width
    maskCanvas.height = height
    const maskCtx = maskCanvas.getContext('2d', { willReadFrequently: true })
    if (!maskCtx) {
      setError('æ— æ³•åˆ›å»º Mask Canvas ä¸Šä¸‹æ–‡')
      return
    }
    maskCanvasRef.current = maskCanvas
    maskCtxRef.current = maskCtx

    // åˆ›å»ºç²’å­ç³»ç»Ÿï¼ˆä¸€æ¬¡æ€§åˆ›å»ºï¼Œä¸å†æ›´æ–°ä½ç½®ï¼‰
    const count = width * height
    console.log(`åˆ›å»º GPU Shader ç²’å­ç³»ç»Ÿ: ${count} ä¸ªç²’å­ (${width}x${height})`)
    const geometry = new THREE.BufferGeometry()
    geometryRef.current = geometry

    const positions = new Float32Array(count * 3)
    const uvs = new Float32Array(count * 2)

    let i = 0
    let j = 0
    for (let y = 0; y < height; y++) {
      for (let x = 0; x < width; x++) {
        positions[i++] = x - width / 2
        positions[i++] = height / 2 - y
        positions[i++] = 0

        uvs[j++] = x / width
        uvs[j++] = y / height
      }
    }

    geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3))
    geometry.setAttribute('uv', new THREE.BufferAttribute(uvs, 2))

    // åˆ›å»ºè§†é¢‘çº¹ç†
    const video = videoRef.current
    const videoTexture = new THREE.VideoTexture(video)
    videoTexture.minFilter = THREE.LinearFilter
    videoTexture.magFilter = THREE.LinearFilter
    videoTexture.format = THREE.RGBAFormat
    videoTextureRef.current = videoTexture

    // åˆ›å»º mask çº¹ç†ï¼ˆåˆå§‹ä¸ºé»‘è‰²ï¼‰
    const maskTexture = new THREE.CanvasTexture(maskCanvas)
    maskTexture.minFilter = THREE.LinearFilter
    maskTexture.magFilter = THREE.LinearFilter
    maskTextureRef.current = maskTexture

    // åˆ›å»º ShaderMaterial
    const material = new THREE.ShaderMaterial({
      uniforms: {
        uVideo: { value: videoTexture },
        uMask: { value: maskTexture },
        uTime: { value: 0 }
      },
      vertexShader,
      fragmentShader,
      transparent: true,
      depthTest: true,
      depthWrite: false
    })
    materialRef.current = material

    const particles = new THREE.Points(geometry, material)
    scene.add(particles)
    particlesRef.current = particles

    // è§†é¢‘åŠ è½½äº‹ä»¶
    const handleLoadedData = () => {
      console.log('è§†é¢‘æ•°æ®å·²åŠ è½½')
      setIsLoading(false)
      setError(null)
    }

    const handleCanPlay = () => {
      setIsLoading(false)
    }

    const handleError = (e: Event) => {
      const videoError = video.error
      let errorMessage = 'è§†é¢‘åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥è§†é¢‘è·¯å¾„'
      if (videoError) {
        switch (videoError.code) {
          case videoError.MEDIA_ERR_ABORTED:
            errorMessage = 'è§†é¢‘åŠ è½½è¢«ä¸­æ­¢'
            break
          case videoError.MEDIA_ERR_NETWORK:
            errorMessage = 'ç½‘ç»œé”™è¯¯ï¼Œæ— æ³•åŠ è½½è§†é¢‘'
            break
          case videoError.MEDIA_ERR_DECODE:
            errorMessage = 'è§†é¢‘è§£ç å¤±è´¥'
            break
          case videoError.MEDIA_ERR_SRC_NOT_SUPPORTED:
            errorMessage = 'è§†é¢‘æ ¼å¼ä¸æ”¯æŒ'
            break
        }
      }
      setError(errorMessage)
      setIsLoading(false)
    }

    video.addEventListener('loadeddata', handleLoadedData)
    video.addEventListener('canplay', handleCanPlay)
    video.addEventListener('error', handleError)

    // æ›´æ–°åˆ†å‰²ï¼ˆèŠ‚æµï¼‰
    async function updateSegmentation(video: HTMLVideoElement) {
      if (!video.videoWidth || !segmentationRef.current) return

      const now = performance.now()
      if (now - lastSegTimeRef.current > 100) {
        // çº¦ 10 FPS
        try {
          await segmentationRef.current.send({ image: video })
          lastSegTimeRef.current = now
        } catch (err: any) {
          if (err?.message?.includes('Aborted') || err?.message?.includes('Module')) {
            console.warn('MediaPipe è¿è¡Œæ—¶é”™è¯¯ï¼Œå°†ä½¿ç”¨åŸºç¡€ç²’å­æ•ˆæœ')
            segmentationRef.current = null
          }
        }
      }
    }

    // æ›´æ–° mask çº¹ç†
    function updateMaskTexture() {
      if (personMaskRef.current && maskCtx) {
        maskCtx.clearRect(0, 0, width, height)
        maskCtx.drawImage(personMaskRef.current, 0, 0, width, height)
        if (maskTextureRef.current) {
          maskTextureRef.current.needsUpdate = true
        }
      }
    }

    // åŠ¨ç”»å¾ªç¯
    function animate() {
      animationFrameRef.current = requestAnimationFrame(animate)

      const camera = cameraRef.current
      const renderer = rendererRef.current
      const scene = sceneRef.current
      const video = videoRef.current
      const material = materialRef.current

      // å§‹ç»ˆæ¸²æŸ“åœºæ™¯
      if (renderer && scene && camera) {
        // æ›´æ–°æ—¶é—´ uniformï¼ˆç”¨äºèƒŒæ™¯æ¼‚æµ®åŠ¨ç”»ï¼‰
        if (material) {
          material.uniforms.uTime.value = performance.now() * 0.001
        }

        // æ›´æ–°åˆ†å‰²ï¼ˆä½é¢‘ï¼‰
        if (video && !video.paused && video.readyState >= 2) {
          updateSegmentation(video)
          updateMaskTexture()
        }

        renderer.render(scene, camera)
      }
    }

    animate()

    // çª—å£å¤§å°è°ƒæ•´
    const handleResize = () => {
      const camera = cameraRef.current
      const renderer = rendererRef.current
      if (!camera || !renderer) return
      camera.aspect = window.innerWidth / window.innerHeight
      camera.updateProjectionMatrix()
      renderer.setSize(window.innerWidth, window.innerHeight)
    }

    window.addEventListener('resize', handleResize)

    // æ¸…ç†
    return () => {
      video.removeEventListener('loadeddata', handleLoadedData)
      video.removeEventListener('canplay', handleCanPlay)
      video.removeEventListener('error', handleError)
      window.removeEventListener('resize', handleResize)
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current)
      }
      if (renderer.domElement.parentNode) {
        renderer.domElement.parentNode.removeChild(renderer.domElement)
      }
      renderer.dispose()
      geometry.dispose()
      material.dispose()
      videoTexture.dispose()
      maskTexture.dispose()
      if (segmentationRef.current) {
        try {
          segmentationRef.current.close()
        } catch (err) {
          console.warn('å…³é—­åˆ†å‰²å™¨å¤±è´¥:', err)
        }
      }
    }
  }, [width, height, particleSize])

  // å¤„ç†è§†é¢‘æºå˜åŒ–
  useEffect(() => {
    if (videoRef.current && videoRef.current.src !== videoSrc) {
      setIsLoading(true)
      setError(null)
      setIsPlaying(false)
      videoRef.current.src = videoSrc
      videoRef.current.load()
    }
  }, [videoSrc])

  // æ’­æ”¾æ§åˆ¶
  const togglePlay = () => {
    if (videoRef.current) {
      if (isPlaying) {
        videoRef.current.pause()
        setIsPlaying(false)
      } else {
        videoRef.current.play().catch((err) => {
          console.error('æ’­æ”¾å¤±è´¥:', err)
          setError('è§†é¢‘æ’­æ”¾å¤±è´¥ï¼Œå¯èƒ½éœ€è¦ç”¨æˆ·äº¤äº’')
          setIsPlaying(false)
        })
        setIsPlaying(true)
      }
    }
  }

  // ç›‘å¬è§†é¢‘æ’­æ”¾çŠ¶æ€
  useEffect(() => {
    const video = videoRef.current
    if (!video) return

    const handlePlay = () => setIsPlaying(true)
    const handlePause = () => setIsPlaying(false)
    const handleEnded = () => setIsPlaying(false)

    video.addEventListener('play', handlePlay)
    video.addEventListener('pause', handlePause)
    video.addEventListener('ended', handleEnded)

    return () => {
      video.removeEventListener('play', handlePlay)
      video.removeEventListener('pause', handlePause)
      video.removeEventListener('ended', handleEnded)
    }
  }, [])

  return (
    <div className={`relative w-full h-screen ${className}`}>
      <div ref={containerRef} className="absolute inset-0" />
      <video
        ref={videoRef}
        src={videoSrc}
        className="hidden"
        loop
        muted
        playsInline
        preload="auto"
      />

      {isLoading && (
        <div className="absolute inset-0 flex flex-col items-center justify-center bg-black/50 z-10">
          <div className="text-white text-lg mb-2">åŠ è½½ä¸­...</div>
          <div className="text-white/60 text-sm">æ­£åœ¨åˆå§‹åŒ– GPU Shader å’Œ MediaPipe</div>
        </div>
      )}

      {error && (
        <div className="absolute inset-0 flex items-center justify-center bg-black/80 z-10">
          <div className="text-red-400 text-center px-4">
            <p className="text-lg mb-2">é”™è¯¯</p>
            <p className="text-sm">{error}</p>
          </div>
        </div>
      )}

      {!isLoading && !error && (
        <div className="absolute bottom-4 left-1/2 transform -translate-x-1/2 z-10 flex flex-col items-center gap-2">
          <button
            onClick={togglePlay}
            className="px-6 py-2 bg-white/20 backdrop-blur-sm text-white rounded-lg hover:bg-white/30 transition-colors"
          >
            {isPlaying ? 'æš‚åœ' : 'æ’­æ”¾'}
          </button>
          <div className="text-white/60 text-xs text-center">
            {hasMask ? 'âœ“ GPU Shader + MediaPipe å·²å°±ç»ª' : 'â³ ç­‰å¾… MediaPipe åˆå§‹åŒ–...'}
          </div>
        </div>
      )}
    </div>
  )
}
```

## åã€æ€§èƒ½å¯¹æ¯”

| æ–¹æ¡ˆ | ç²’å­æ•°é‡ | FPS | CPU å ç”¨ | GPU å ç”¨ |
|------|---------|-----|----------|----------|
| CPU ç‰ˆï¼ˆBufferAttributeï¼‰ | 6,400 | 30-60 | é«˜ | ä½ |
| CPU ç‰ˆï¼ˆBufferAttributeï¼‰ | 57,600 | < 20 | å¾ˆé«˜ | ä½ |
| **GPU Shader ç‰ˆ** | **57,600** | **60** | **ä½** | **ä¸­** |
| **GPU Shader ç‰ˆ** | **115,200** | **60** | **ä½** | **ä¸­** |

## åä¸€ã€å…³é”®ä¼˜åŒ–ç‚¹

### 1. ç²’å­ä½ç½®é™æ€åŒ–
- âœ… ä½ç½®åˆ›å»ºåä¸å†æ›´æ–°
- âœ… æ‰€æœ‰è®¡ç®—åœ¨ GPU Shader ä¸­å®Œæˆ

### 2. çº¹ç†æ›´æ–°æœºåˆ¶
- âœ… VideoTexture è‡ªåŠ¨æ›´æ–°
- âœ… Mask çº¹ç†æŒ‰éœ€æ›´æ–°ï¼ˆ`needsUpdate = true`ï¼‰

### 3. Shader è®¡ç®—
- âœ… è§†é¢‘é‡‡æ ·åœ¨ Fragment Shader
- âœ… æ·±åº¦è®¡ç®—åœ¨ Vertex Shader
- âœ… ç²’å­å¤§å°åœ¨ Vertex Shader

### 4. å‡å°‘ CPU è´Ÿæ‹…
- âœ… ä¸å¾ªç¯æ›´æ–°ç²’å­ä½ç½®
- âœ… ä¸æ›´æ–° BufferAttribute
- âœ… åªæ›´æ–° uniformï¼ˆæ—¶é—´ï¼‰

## åäºŒã€Shader å‚æ•°è°ƒèŠ‚

### æ·±åº¦æ§åˆ¶

```glsl
// äººç‰©æ·±åº¦
pos.z += brightness * 60.0;  // å¯è°ƒèŠ‚ï¼š30-100

// èƒŒæ™¯æ·±åº¦
pos.z += brightness * 15.0;   // å¯è°ƒèŠ‚ï¼š5-30
```

### ç²’å­å¤§å°

```glsl
// äººç‰©ç²’å­å¤§å°
gl_PointSize = mask > 0.5 ? 2.8 : 1.2;  // å¯è°ƒèŠ‚ï¼š2.0-4.0 / 1.0-2.0
```

### èƒŒæ™¯é€æ˜åº¦

```glsl
// èƒŒæ™¯é€æ˜åº¦ï¼ˆæ›´è™šï¼‰
float alpha = vIsPerson > 0.5 ? 1.0 : 0.45;  // å¯è°ƒèŠ‚ï¼š0.3-0.6
```

### èƒŒæ™¯æ¼‚æµ®ï¼ˆå¯é€‰ï¼‰

```glsl
// èƒŒæ™¯è½»å¾®æ¼‚æµ®
pos.z += sin(uTime + position.x * 0.05) * 5.0;  // å¯è°ƒèŠ‚ï¼š0-10
```

## åä¸‰ã€ä½¿ç”¨ç¤ºä¾‹

```tsx
import ShaderVideoParticle from '@/components/ShaderVideoParticle'

export default function ShaderGamePage() {
  return (
    <div className="min-h-screen bg-black">
      <ShaderVideoParticle
        videoSrc="/videos/sample.mp4"
        width={320}
        height={180}
        particleSize={2}
      />
    </div>
  )
}
```

## åå››ã€ä¸ CPU ç‰ˆæœ¬çš„åŒºåˆ«

| ç‰¹æ€§ | CPU ç‰ˆ | GPU Shader ç‰ˆ |
|------|--------|---------------|
| ç²’å­ä½ç½®æ›´æ–° | æ¯å¸§æ›´æ–° BufferAttribute | é™æ€ï¼Œä¸æ›´æ–° |
| é¢œè‰²æ›´æ–° | JS å¾ªç¯æ›´æ–° | GPU é‡‡æ ·çº¹ç† |
| æ·±åº¦è®¡ç®— | JS å¾ªç¯è®¡ç®— | GPU Vertex Shader |
| ç²’å­å¤§å° | å…¨å±€ç»Ÿä¸€ | æ¯ä¸ªç²’å­ç‹¬ç«‹ï¼ˆShaderï¼‰ |
| æ€§èƒ½ | < 2 ä¸‡ç²’å­æµç•… | 10 ä¸‡+ ç²’å­æµç•… |
| CPU å ç”¨ | é«˜ | ä½ |
| GPU å ç”¨ | ä½ | ä¸­ |

## åäº”ã€æ³¨æ„äº‹é¡¹

### 1. WebGL æ”¯æŒ
- éœ€è¦æµè§ˆå™¨æ”¯æŒ WebGL 2.0ï¼ˆç°ä»£æµè§ˆå™¨éƒ½æ”¯æŒï¼‰
- ç§»åŠ¨ç«¯æ€§èƒ½å¯èƒ½ç•¥ä½

### 2. çº¹ç†é™åˆ¶
- è§†é¢‘çº¹ç†å¤§å°å— GPU é™åˆ¶
- å»ºè®®è§†é¢‘åˆ†è¾¨ç‡ä¸è¶…è¿‡ 1920x1080

### 3. å†…å­˜å ç”¨
- 10 ä¸‡ç²’å­çº¦å ç”¨ 2-3 MB å†…å­˜
- çº¹ç†å ç”¨å–å†³äºè§†é¢‘åˆ†è¾¨ç‡

### 4. è°ƒè¯•
- Shader é”™è¯¯è¾ƒéš¾è°ƒè¯•
- å»ºè®®å…ˆåœ¨ç®€å•åœºæ™¯æµ‹è¯•

## åå…­ã€è¿›é˜¶ä¼˜åŒ–

### 1. LODï¼ˆç»†èŠ‚å±‚æ¬¡ï¼‰
```glsl
// æ ¹æ®è·ç¦»è°ƒæ•´ç²’å­å¤§å°
float distance = length(cameraPosition - position);
gl_PointSize = distance < 200.0 ? 2.8 : 1.2;
```

### 2. åå¤„ç†æ•ˆæœ
- æ·»åŠ æ¨¡ç³Šæ•ˆæœ
- æ·»åŠ å‘å…‰æ•ˆæœ
- æ·»åŠ è‰²å½©è°ƒæ•´

### 3. å¤šè§†é¢‘æ”¯æŒ
- ä½¿ç”¨å¤šä¸ª VideoTexture
- Shader ä¸­æ··åˆå¤šä¸ªè§†é¢‘

## åä¸ƒã€æ€»ç»“

GPU Shader ç‰ˆæœ¬çš„æ ¸å¿ƒä¼˜åŠ¿ï¼š

1. **æ€§èƒ½**ï¼š10 ä¸‡+ ç²’å­ç¨³å®š 60 FPS
2. **çµæ´»æ€§**ï¼šæ¯ä¸ªç²’å­ç‹¬ç«‹æ§åˆ¶å¤§å°ã€æ·±åº¦ã€é€æ˜åº¦
3. **CPU å‹å¥½**ï¼šCPU åªè´Ÿè´£è§†é¢‘è§£ç å’Œ MediaPipe
4. **å¯æ‰©å±•**ï¼šæ˜“äºæ·»åŠ æ›´å¤šè§†è§‰æ•ˆæœ

**é€‚ç”¨åœºæ™¯**ï¼š
- éœ€è¦å¤§é‡ç²’å­çš„åœºæ™¯
- éœ€è¦ç²¾ç»†æ§åˆ¶æ¯ä¸ªç²’å­çš„åœºæ™¯
- æ€§èƒ½è¦æ±‚é«˜çš„åœºæ™¯
